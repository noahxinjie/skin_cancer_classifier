{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# With normalization\n",
    "\n",
    "# %%\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights\n",
    "\n",
    "# %%\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# %%\n",
    "# Train-val split\n",
    "data_dir = '../isic2019_modiified/isic2019_modified'\n",
    "train_dir = f'{data_dir}/train'\n",
    "val_dir = f'{data_dir}/val'\n",
    "\n",
    "num_classes = 5  # Change this based on your dataset\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "class_weights_tensor = torch.tensor([0.4637030299585015, 0.20220567335569326, 0.2313683133420499, 0.033141947586834176, 0.06958103575692115], dtype=torch.float).to(device)\n",
    "\n",
    "# %%\n",
    "# Define transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.6521, 0.5233, 0.5159], std=[0.2284, 0.2071, 0.2186])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.6521, 0.5233, 0.5159], std=[0.2284, 0.2071, 0.2186])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# %%\n",
    "# Load datasets\n",
    "image_datasets = {\n",
    "    'train': datasets.ImageFolder(train_dir, data_transforms['train']),\n",
    "    'val': datasets.ImageFolder(val_dir, data_transforms['val']),\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True, num_workers=4),\n",
    "    'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=False, num_workers=4),\n",
    "}\n",
    "\n",
    "\n",
    "# %%\n",
    "class MobileNetCustom(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MobileNetCustom, self).__init__()\n",
    "        weights = MobileNet_V3_Large_Weights.IMAGENET1K_V2 # Load pretrained mobilenet\n",
    "        self.mobilenet = mobilenet_v3_large(weights=weights)\n",
    "\n",
    "        num_input_features = 960\n",
    "\n",
    "        # Replace the last fully connected layer with a new one\n",
    "        self.mobilenet.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),  # Dropout layer to reduce overfitting\n",
    "            nn.Linear(num_input_features, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through MobileNet backbone\n",
    "        x = self.mobilenet.features(x)\n",
    "\n",
    "        # Global Average Pooling (GAP)\n",
    "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
    "\n",
    "        # Flatten feature map\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # Forward pass through custom classifier\n",
    "        x = self.mobilenet.classifier(x)\n",
    "        return x\n",
    "\n",
    "# %%\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "model = MobileNetCustom(num_classes).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch 1, Loss: 0.5968\n",
      "Validation Accuracy after epoch 1: 0.5606, Loss: 1.2766\n",
      "Model saved as best_model_with_norm.pth\n",
      "Epoch 2, Loss: 0.4824\n",
      "Validation Accuracy after epoch 2: 0.6738, Loss: 1.0206\n",
      "Model saved as best_model_with_norm.pth\n",
      "Epoch 3, Loss: 0.4050\n",
      "Validation Accuracy after epoch 3: 0.7235, Loss: 0.7055\n",
      "Model saved as best_model_with_norm.pth\n",
      "Epoch 4, Loss: 0.3511\n",
      "Validation Accuracy after epoch 4: 0.7156, Loss: 0.8640\n",
      "Epoch 5, Loss: 0.2847\n",
      "Validation Accuracy after epoch 5: 0.7093, Loss: 0.9184\n",
      "Epoch 6, Loss: 0.2406\n",
      "Validation Accuracy after epoch 6: 0.7474, Loss: 0.8550\n",
      "Model saved as best_model_with_norm.pth\n",
      "Epoch 7, Loss: 0.1944\n",
      "Validation Accuracy after epoch 7: 0.7184, Loss: 1.0297\n",
      "Epoch 8, Loss: 0.1737\n",
      "Validation Accuracy after epoch 8: 0.7403, Loss: 1.0374\n",
      "Epoch 9, Loss: 0.1438\n",
      "Validation Accuracy after epoch 9: 0.7403, Loss: 0.8395\n",
      "Epoch 10, Loss: 0.1332\n",
      "Validation Accuracy after epoch 10: 0.7378, Loss: 0.9936\n",
      "Epoch 11, Loss: 0.1148\n",
      "Validation Accuracy after epoch 11: 0.7585, Loss: 0.9532\n",
      "Model saved as best_model_with_norm.pth\n",
      "Epoch 12, Loss: 0.0985\n",
      "Validation Accuracy after epoch 12: 0.7435, Loss: 1.0230\n",
      "Epoch 13, Loss: 0.0997\n",
      "Validation Accuracy after epoch 13: 0.7483, Loss: 1.0744\n",
      "Epoch 14, Loss: 0.0802\n",
      "Validation Accuracy after epoch 14: 0.7304, Loss: 1.2215\n",
      "Epoch 15, Loss: 0.0842\n",
      "Validation Accuracy after epoch 15: 0.7474, Loss: 1.1934\n",
      "Epoch 16, Loss: 0.0905\n",
      "Validation Accuracy after epoch 16: 0.7321, Loss: 1.0292\n",
      "Epoch 17, Loss: 0.0750\n",
      "Validation Accuracy after epoch 17: 0.7395, Loss: 1.1651\n",
      "Epoch 18, Loss: 0.0687\n",
      "Validation Accuracy after epoch 18: 0.7560, Loss: 1.0169\n",
      "Epoch 19, Loss: 0.0680\n",
      "Validation Accuracy after epoch 19: 0.7634, Loss: 1.0255\n",
      "Model saved as best_model_with_norm.pth\n",
      "Epoch 20, Loss: 0.0640\n",
      "Validation Accuracy after epoch 20: 0.7420, Loss: 1.4409\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# Training loop\n",
    "print(\"Start training\")\n",
    "best_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in dataloaders['train']:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloaders[\"train\"]) \n",
    "    print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    # After each epoch, evaluate accuracy on the validation set\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloaders['val']:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item()\n",
    "            correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    epoch_acc = correct / total \n",
    "    val_epoch_loss = val_running_loss / len(dataloaders[\"val\"])\n",
    "\n",
    "    print(f'Validation Accuracy after epoch {epoch+1}: {epoch_acc:.4f}, Loss: {val_epoch_loss:.4f}')\n",
    "\n",
    "    # Save the model if it has a better accuracy than the best model seen so far\n",
    "    if epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        torch.save(model.state_dict(), 'mobilenet_224_best_with_norm.pth')\n",
    "        print('Model saved as mobilenet_224_best_with_norm.pth')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7641\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import torchvision.transforms as transforms \n",
    "import torchvision.datasets as datasets \n",
    "from torch.utils.data import DataLoader \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import matthews_corrcoef, precision_score, recall_score, f1_score, confusion_matrix \n",
    "import seaborn as sns  # For a nicer confusion matrix plot \n",
    "test_transforms = transforms.Compose([ \n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.6521, 0.5233, 0.5159], std=[0.2284, 0.2071, 0.2186]) \n",
    "]) \n",
    " \n",
    "test_dir = '../isic2019_modified/isic2019_modified/test'  # specify the path to your test data \n",
    "image_datasets['test'] = datasets.ImageFolder(test_dir, test_transforms) \n",
    " \n",
    "dataloaders['test'] = torch.utils.data.DataLoader( \n",
    "    image_datasets['test'], \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=4 \n",
    ") \n",
    " \n",
    "# Load the model \n",
    "model = MobileNetCustom(num_classes) \n",
    "model.load_state_dict(torch.load('mobilenet_224_best_with_norm.pth', map_location=torch.device('cpu')))\n",
    "# model.load_state_dict(torch.load('best_model_with_norm_and_trans_big.pth')) \n",
    "model.to(device) \n",
    "model.eval()  # Set model to evaluation mode \n",
    " \n",
    "# Initialize the prediction and actual label lists \n",
    "test_predictions = [] \n",
    "test_actual = [] \n",
    " \n",
    "# Ensure the test loader is correctly set \n",
    "test_loader = dataloaders['test'] \n",
    " \n",
    "with torch.no_grad(): \n",
    "    for images, labels in test_loader: \n",
    "        images = images.to(device) \n",
    "        labels = labels.to(device) \n",
    "        outputs = model(images) \n",
    "         \n",
    "        _, predicted = torch.max(outputs.data, 1) \n",
    "        test_predictions.extend(predicted.view(-1).cpu().numpy()) \n",
    "        test_actual.extend(labels.view(-1).cpu().numpy()) \n",
    " \n",
    "# Convert lists to numpy arrays \n",
    "test_predictions = np.array(test_predictions) \n",
    "test_actual = np.array(test_actual) \n",
    " \n",
    "# Calculate metrics \n",
    "test_accuracy = np.mean(test_predictions == test_actual) \n",
    "precision = precision_score(test_actual, test_predictions, average='weighted') \n",
    "recall = recall_score(test_actual, test_predictions, average='weighted') \n",
    "f1 = f1_score(test_actual, test_predictions, average='weighted')\n",
    "\n",
    "mcc = matthews_corrcoef(test_actual, test_predictions)\n",
    " \n",
    "print(f'Test Accuracy: {test_accuracy:.4f}') \n",
    "print(f'Precision: {precision:.4f}') \n",
    "print(f'Recall: {recall:.4f}') \n",
    "print(f'F1 Score: {f1:.4f}') \n",
    "print(f'MCC: {mcc:.4f}')\n",
    "\n",
    "# Function to plot the confusion matrix \n",
    "def plot_confusion_matrix(cm, class_names): \n",
    "    plt.figure(figsize=(10, 7)) \n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=class_names, yticklabels=class_names) \n",
    "    plt.xlabel('Predicted labels') \n",
    "    plt.ylabel('True labels') \n",
    "    plt.title('Confusion Matrix') \n",
    "    plt.show() \n",
    " \n",
    "# Compute and plot confusion matrix \n",
    "cm = confusion_matrix(test_actual, test_predictions) \n",
    "plot_confusion_matrix(cm, class_names=['BKL-NV', 'BSCC', 'MEL', 'Normal', 'UNK'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
